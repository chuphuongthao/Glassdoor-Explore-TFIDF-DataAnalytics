JOB DESCRIPTION
Bank of America is looking for a Data Engineer to join the Global Markets Risk Analytics team. This team is split between Chicago, Jersey City, and have London partners. This team consists of Risk Analysts and other technical engineers, but are working to support Sr. Risk Managers/Executives across the globe. You will start your day with a team scrum meeting to talk through what you’re building/working on, break throughs, issues, discuss open tickets, etc. After the daily scrum, you will write code, extract data, understand the data and figure out how you should use/present this data to the Executives within prime brokerage, swaps, securities, etc. This is a very data focused/technical role – you need to translate the data into a story. This group works with their own in-house libraries with advanced capabilities, so you will get incredible exposure to Bank of America’s risk systems. They have many exciting projects coming up in 2022/2023, in addition to their business-as-usual and regulatory work load.

Managing multiple data engineering and software development targets using agile or SDLC lifecycle methodologies where you will be expected to have managed a delivery of key phases including coding, unit testing, build, and release cycles.
Leverage your prior experience to build and deploy data engineering and extraction functions with light to moderate mathematical or statistical skills. You will use programming languages such as Python, SQL to build the data extraction routines to feed into end-user reports.Import data from different systems, cleanse the data, enrich and augment.Visualize data into useful dashboardsGenerate and maintain adhoc reports to answer mission critical risk controls and provide business insights from large data sets with millions of rows and 100s of attributes.
You will be part of a core data engineering team building out a data warehouse that will serve as the basis for risk intelligence capabilities. This data warehouse will be based on advanced distributed technologies – HDFS (incl PYhDfs), Sparck, Hive, Impala, Pig, Sqoop and Yarn. It will form the basis for our next generation of anomalous data detection reports and will leverage machine learning algorithms.
MINIMUM REQUIREMENTS3+ years of Data Engineering experience
Python & SQL scriptingBachelor’s or Master’s Degree in Financial Engineering, Financial Mathematics, Economics, Statistics, etcGlobal markets/Capital Markets/Financial Services background
DESIRED SKILLSData Science experienceData reconciliation experience with new systems (ex: General Ledger) 