Overview:Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming analytics landscape.Looking for Data Migration Engineer having an experience migrating data from on prem to cloud.Must Have: AWS (S3, Aethna, EMR, EC2), Python, Spark, PySparkGood to have: SnowflakeRequirements:Candidate must be experienced working in projects involving data migration on AWSExperience on data migration from On-Prem databases to AWS Cloud on S3Understands where to obtain information needed to make the appropriate decisionsDemonstrates ability to break down a problem to manageable pieces and implement effective, timely solutionsIdentifies the problem versus the symptomsManages problems that require involvement of others to solveReaches sound decisions quicklyDevelops solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unitRoles & resposibilities:Acts as a single point of contact for data migration to AWS projects for customerProvides innovative and cost-effective solution using AWS, Spark, python & customer suggested toolsetOptimizes the use of all available resourcesDevelops solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unitAs a leader in the Cloud Engineering you will be responsible for the overseeing developmentLearn/adapt quickly to new Technologies as per the business needDevelop a team of Operations Excellence, building tools and capabilities that the Development teams leverage to maintain high levels of performance, scalability, security and availabilitySkills:The Candidate must have 3-5 yrs of experience in AWS, PySpark & PythonHands on experience on AWS Cloud platform especially S3, lamda, EC2, EMRExperience on spark scriptingHas working knowledge on migrating relational and dimensional databases on AWS Cloud platformRelevent experience with ETL methods and with retrieving data from dimensional data models and data warehouses.Strong experience with relational databases and data access methods, especially SQL.Knowledge of Amazon AWS architecture and designMinimum QualificationsBachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.Skills-Around 15+ Years Overall Experience in ITAround 5+ Years experience in Insurance P&C domainDatabase - Teradata or equivalentETL - Ab Initio or Talend or equivalentReporting - Cognos, MicroStrategy, Qliksense or equivalentCloud - AWSResponsibilities:> Experience working directly with CXOs delegates to deliver transformational initiatives> Experience in managing program level engagements with multiple workstreams and client stakeholders> Experience in delivery of complex consulting projects in Data & Analytics practices> Should have good understanding of data, technology and organizational challenges facing Financial, Risk and Operations> Act as Onshore co-ordinator to mentor/guide offshore team> Ability to work quickly and independently with little oversight> Own and manage role implementation and enablement of Data Solution Architects worldwide> Facilitate the discovery of entities, attributes, relationships, and business rules from the functional experts and the user community.> Lead/Assist with architectural strategic thinking, information solutions and road maps to drive architectural recommendations> Collaborate with Business leaders to determine how to best use technology to enable growth and success (e.g. operation reporting and advance analytics).> Understand potential impacts of proposed solutions on other systems, processes or projects. Articulates and document data designs, considering tradeoffs, cost and benefits> Within the governance process, assist in the development of blue prints and design reviews to ensure architectural compliance of solution> Provide information architecture services to project teams as per Traveler’s standards.> Design, coordinate and execute pilots, prototypes or proof of concepts, provide validation on specific scenarios and provide deployment guidance> Working knowledge of data integration frameworks Talend or ab initio> Working knowledge of Data on Cloud tools - AWS S3, Snowflake, databricks> Contributing to ongoing improvement of methods employed towards Continuous improvement> Drive technical vision and architecture designs to consensus across multiple teams"Enterprise team is seeking highly motivated and skilled Data & Analytics Engineer to provide the design, development, and delivery of data and analytical solutions in support of our Enterprise. The Data Engineer provides oversight and implementation approaches that benefit business strategic initiativesMust have Skillset: Talend, AWS , SparkNice to have: AWS Lambda, AWS Step functions, AutoSys, SQL server, Databricks, SnowflakePrimary Job Duties & Responsibilities:Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.Design complex data solutionsPerform analysis of complex sources to determine value and use and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.Test data movement, transformation code, and data componentsMinimum Qualifications:Bachelor's degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.Education, Work Experience, & Knowledge:Bachelor's Degree in STEM related field or equivalent.Eight years of related experience.Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.4+ years of experience in Programming Languages: Python, Spark, SQL2+ years of experience in Cloud Platforms: AWS (Preferred), Azure, GCPPrior experience in leading data engineering teams that have built production data pipelines processing languages and a full understanding of modern software engineering practicesHands-on experience in a primary ETL tool (Talend, AWS Glue etc.)Cloud Orchestration & Automation: Jenkins Pipelines, AWS Lambda, AWS Step functions, AutoSysDatabase: Relational Databases (SQL Server etc.)Preferred Skills: Databricks, SnowflakeJob Specific Technical Skills & Competencies:The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.Job Type: ContractSalary: $75.00 - $85.00 per hourSchedule:8 hour shiftExperience:AWS: 5 years (Preferred)python: 5 years (Preferred)Spark: 5 years (Required)snowflake: 4 years (Required)IT: 10 years (Required)Work Location: One location 